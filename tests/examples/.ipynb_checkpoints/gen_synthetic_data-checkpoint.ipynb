{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "general-payroll",
   "metadata": {},
   "source": [
    "## **Adversarial PCA** - Generate Synthetic Data\n",
    "\n",
    "File:  gen_synthetic_data.ipynb\n",
    "\n",
    "Author:  Billy Carson\n",
    "\n",
    "Date written:  04-10-2021\n",
    "\n",
    "Last modified:  04-11-2021\n",
    "\n",
    "> Description: This script generates two synthetic datasets to use as an examples for decomposition with adversarial Principal Component Analysis (aPCA) as well as demonstrate the difference in behavior of aPCA variants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-longitude",
   "metadata": {},
   "source": [
    "### **Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "generous-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy.random import RandomState, SeedSequence\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import aPCA and utilities modules\n",
    "sys.path.append('..')\n",
    "from adv_pca import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-security",
   "metadata": {},
   "source": [
    "### **Set random seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "engaged-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state\n",
    "random_state = 4\n",
    "rng = np.random.default_rng(random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-idaho",
   "metadata": {},
   "source": [
    "## **Synthetic data example 1** - Concomitant data independent of class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-climate",
   "metadata": {},
   "source": [
    "### **Generate synthetic data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "embedded-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary data - Function of both class and concomitant data\n",
    "# Concomitant data - Random function, no relation to class\n",
    "\n",
    "# Number of total samples\n",
    "n_samp = 10000\n",
    "\n",
    "# Number of samples in class 1 and class 2\n",
    "n_samp_1 = int(n_samp / 2)\n",
    "n_samp_2 = n_samp - int(n_samp / 2)\n",
    "\n",
    "# Latent factor phi mean arrays\n",
    "phi_1_mean = np.array([0.2, -0.1, 0.5])\n",
    "phi_2_mean = np.array([-0.3, 0.1, -0.4])\n",
    "\n",
    "# Latent factor phi covariance matrices\n",
    "# phi_1_sigma = np.array([[1.0, 0.9, 0.0],\n",
    "#                       [0.9, 1.0, 0.1],\n",
    "#                       [0.0, 0.1, 1.0]])\n",
    "# phi_2_sigma = np.array([[1.0, 0.1, 0.9],\n",
    "#                       [0.1, 1.0, 0.5],\n",
    "#                       [0.9, 0.5, 1.0]])\n",
    "phi_1_sigma = np.array([[1.0, 0.7, 0.0],\n",
    "                      [0.7, 1.0, 0.1],\n",
    "                      [0.0, 0.1, 1.0]])\n",
    "phi_2_sigma = np.array([[1.0, 0.1, 0.6],\n",
    "                      [0.1, 1.0, 0.4],\n",
    "                      [0.6, 0.4, 1.0]])\n",
    "\n",
    "# Generate latent data uncorrupted by noise\n",
    "phi_1 = rng.multivariate_normal(phi_1_mean, phi_1_sigma, size=(n_samp_1))\n",
    "phi_2 = rng.multivariate_normal(phi_2_mean, phi_2_sigma, size=(n_samp_2))\n",
    "\n",
    "# Observed concomitant data is a linear combination of the true concomitant data and some Gaussian noise\n",
    "Y_sigma = 7.0\n",
    "Y_true = rng.normal(0.0, Y_sigma, size=(n_samp, 1))\n",
    "noise_sigma = 0.2\n",
    "Y_eps = rng.normal(0.0, noise_sigma, size=(n_samp, 1))\n",
    "Y = Y_true.copy() + Y_eps\n",
    "\n",
    "# Observed primary data is a linear combination of latent data phi, concomitant data Y, and Gaussian noise\n",
    "X_eps = rng.normal(0.0, noise_sigma, size=(n_samp, 1))\n",
    "X = np.concatenate((phi_1, phi_2), axis=0) + Y_true + X_eps\n",
    "\n",
    "# Create primairy data labels\n",
    "labels_1 = np.full(shape=(n_samp_1), fill_value=0)\n",
    "labels_2 = np.full(shape=(n_samp_2), fill_value=1)\n",
    "labels = np.hstack((labels_1, labels_2))\n",
    "\n",
    "# Save synthetic data\n",
    "np.save('synthetic_data/X_synth_1', X)\n",
    "np.save('synthetic_data/Y_synth_1', Y)\n",
    "np.save('synthetic_data/labels_synth_1', labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-english",
   "metadata": {},
   "source": [
    "## **Synthetic data example 2** - Concomitant data *dependent* on class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-valentine",
   "metadata": {},
   "source": [
    "### **Generate synthetic data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handled-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary data - Function of both class and concomitant data\n",
    "# Concomitant data - Function of class\n",
    "\n",
    "# Number of total samples\n",
    "n_samp = 10000\n",
    "\n",
    "# Number of samples in class 1 and class 2\n",
    "n_samp_1 = int(n_samp / 2)\n",
    "n_samp_2 = n_samp - int(n_samp / 2)\n",
    "\n",
    "# Latent factor phi mean arrays\n",
    "phi_1_mean = np.array([0.2, -0.1, 0.5])\n",
    "phi_2_mean = np.array([-0.3, 0.1, -0.4])\n",
    "\n",
    "# Latent factor phi covariance matrices\n",
    "phi_1_sigma = np.array([[1.0, 0.9, 0.0],\n",
    "                      [0.9, 1.0, 0.1],\n",
    "                      [0.0, 0.1, 1.0]])\n",
    "phi_2_sigma = np.array([[1.0, 0.1, 0.9],\n",
    "                      [0.1, 1.0, 0.5],\n",
    "                      [0.9, 0.5, 1.0]])\n",
    "\n",
    "# Generate latent data uncorrupted by noise\n",
    "phi_1 = rng.multivariate_normal(phi_1_mean, phi_1_sigma, size=(n_samp_1))\n",
    "phi_2 = rng.multivariate_normal(phi_2_mean, phi_2_sigma, size=(n_samp_2))\n",
    "\n",
    "# Concomitant data now has mean dependent on class\n",
    "Y_sigma = 7.0\n",
    "Y_1_true = rng.normal(1.0, Y_sigma, size=(n_samp_1, 1))\n",
    "Y_2_true = rng.normal(-1.0, Y_sigma, size=(n_samp_2, 1))\n",
    "noise_sigma = 0.2\n",
    "Y_eps = rng.normal(0.0, noise_sigma, size=(n_samp, 1))\n",
    "Y_true = np.concatenate((Y_1_true, Y_2_true), axis=0)\n",
    "Y = Y_true + Y_eps\n",
    "\n",
    "# Observed primary data is a linear combination of latent data phi, concomitant data Y, and Gaussian noise\n",
    "X_eps = rng.normal(0.0, noise_sigma, size=(n_samp, 1))\n",
    "X = np.concatenate((phi_1, phi_2), axis=0) + Y_true + X_eps\n",
    "\n",
    "# Create primairy data labels\n",
    "labels_1 = np.full(shape=(n_samp_1), fill_value=0)\n",
    "labels_2 = np.full(shape=(n_samp_2), fill_value=1)\n",
    "labels = np.hstack((labels_1, labels_2))\n",
    "\n",
    "# Save synthetic data\n",
    "np.save('synthetic_data/X_synth_2', X)\n",
    "np.save('synthetic_data/Y_synth_2', Y)\n",
    "np.save('synthetic_data/labels_synth_2', labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
